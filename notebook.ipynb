{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "url = 'http://newsapi.org/v2/top-headlines?sources=the-times-of-india&apiKey=ae5ccbe2006a4debbe6424d7e4b569ec'\n",
    "news = requests.get(url).text\n",
    "news_dict = json.loads(news)\n",
    "articles = news_dict['articles']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(articles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "import wolframalpha\n",
    "\n",
    "nest_asyncio.apply()  # Apply nest_asyncio to the current event loop\n",
    "\n",
    "wolframalpha_id = \"YGJA4P-U3XQJ9JQ6K\"\n",
    "question = \"calculate 1 + 1\"\n",
    "\n",
    "client = wolframalpha.Client(wolframalpha_id)\n",
    "answer = client.query(question)\n",
    "answer = next(answer.results).text\n",
    "print(answer)\n",
    "print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RealtimeTTS import TextToAudioStream, EdgeEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "# --- Gemini API Configuration ---\n",
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if not GOOGLE_API_KEY:\n",
    "    print(\"ðŸ”´ Error: GOOGLE_API_KEY not found in environment variables.\")\n",
    "    print(\"   Please create a .env file with GOOGLE_API_KEY=\\\"YOUR_API_KEY\\\"\")\n",
    "    sys.exit(1)\n",
    "\n",
    "try:\n",
    "    genai.configure(api_key=GOOGLE_API_KEY)\n",
    "    print(\"âœ… Gemini API Configured\")\n",
    "except Exception as e:\n",
    "    print(f\"ðŸ”´ Gemini configuration failed: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# --- Model Initialization ---\n",
    "# Choose your Gemini model (e.g., 'gemini-1.5-flash', 'gemini-pro')\n",
    "MODEL_NAME = 'gemini-1.5-flash'\n",
    "\n",
    "try:\n",
    "    model = genai.GenerativeModel(MODEL_NAME)\n",
    "    # Start a chat session for conversation history\n",
    "    chat = model.start_chat(history=[]) # Gemini uses its own history management\n",
    "    print(f\"âœ… Initialized Gemini Model: {MODEL_NAME}\")\n",
    "except Exception as e:\n",
    "    print(f\"ðŸ”´ Failed to initialize Gemini model: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "with open(\"Jarvis/config/SYSTEM_PROMPT.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    SYSTEM_PROMPT = file.read()\n",
    "initial_history = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"parts\": [SYSTEM_PROMPT]\n",
    "        },\n",
    "    ]\n",
    "\n",
    "chat = model.start_chat(history=initial_history)\n",
    "print(f\"âœ… Initialized Gemini Model: {MODEL_NAME} with Jarvis persona and instructions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Google API Configured\n",
      "\n",
      "--- Available Gemini Models ---\n",
      "Model Name: models/gemini-1.0-pro-vision-latest\n",
      "  Display Name: Gemini 1.0 Pro Vision\n",
      "  Description: The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.\n",
      "  Supported Methods: ['generateContent', 'countTokens']\n",
      "--------------------\n",
      "Model Name: models/gemini-pro-vision\n",
      "  Display Name: Gemini 1.0 Pro Vision\n",
      "  Description: The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.\n",
      "  Supported Methods: ['generateContent', 'countTokens']\n",
      "--------------------\n",
      "Model Name: models/gemini-1.5-pro-latest\n",
      "  Display Name: Gemini 1.5 Pro Latest\n",
      "  Description: Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens.\n",
      "  Supported Methods: ['generateContent', 'countTokens']\n",
      "--------------------\n",
      "Model Name: models/gemini-1.5-pro-001\n",
      "  Display Name: Gemini 1.5 Pro 001\n",
      "  Description: Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.\n",
      "  Supported Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "--------------------\n",
      "Model Name: models/gemini-1.5-pro-002\n",
      "  Display Name: Gemini 1.5 Pro 002\n",
      "  Description: Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in September of 2024.\n",
      "  Supported Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "--------------------\n",
      "Model Name: models/gemini-1.5-pro\n",
      "  Display Name: Gemini 1.5 Pro\n",
      "  Description: Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.\n",
      "  Supported Methods: ['generateContent', 'countTokens']\n",
      "--------------------\n",
      "Model Name: models/gemini-1.5-flash-latest\n",
      "  Display Name: Gemini 1.5 Flash Latest\n",
      "  Description: Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.\n",
      "  Supported Methods: ['generateContent', 'countTokens']\n",
      "--------------------\n",
      "Model Name: models/gemini-1.5-flash-001\n",
      "  Display Name: Gemini 1.5 Flash 001\n",
      "  Description: Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in May of 2024.\n",
      "  Supported Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "--------------------\n",
      "Model Name: models/gemini-1.5-flash-001-tuning\n",
      "  Display Name: Gemini 1.5 Flash 001 Tuning\n",
      "  Description: Version of Gemini 1.5 Flash that supports tuning, our fast and versatile multimodal model for scaling across diverse tasks, released in May of 2024.\n",
      "  Supported Methods: ['generateContent', 'countTokens', 'createTunedModel']\n",
      "--------------------\n",
      "Model Name: models/gemini-1.5-flash\n",
      "  Display Name: Gemini 1.5 Flash\n",
      "  Description: Alias that points to the most recent stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.\n",
      "  Supported Methods: ['generateContent', 'countTokens']\n",
      "--------------------\n",
      "Model Name: models/gemini-1.5-flash-002\n",
      "  Display Name: Gemini 1.5 Flash 002\n",
      "  Description: Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in September of 2024.\n",
      "  Supported Methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "--------------------\n",
      "Model Name: models/gemini-1.5-flash-8b\n",
      "  Display Name: Gemini 1.5 Flash-8B\n",
      "  Description: Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.\n",
      "  Supported Methods: ['createCachedContent', 'generateContent', 'countTokens']\n",
      "--------------------\n",
      "Model Name: models/gemini-1.5-flash-8b-001\n",
      "  Display Name: Gemini 1.5 Flash-8B 001\n",
      "  Description: Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.\n",
      "  Supported Methods: ['createCachedContent', 'generateContent', 'countTokens']\n",
      "--------------------\n",
      "Model Name: models/gemini-1.5-flash-8b-latest\n",
      "  Display Name: Gemini 1.5 Flash-8B Latest\n",
      "  Description: Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.\n",
      "  Supported Methods: ['createCachedContent', 'generateContent', 'countTokens']\n",
      "--------------------\n",
      "Model Name: models/gemini-1.5-flash-8b-exp-0827\n",
      "  Display Name: Gemini 1.5 Flash 8B Experimental 0827\n",
      "  Description: Experimental release (August 27th, 2024) of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model. Replaced by Gemini-1.5-flash-8b-001 (stable).\n",
      "  Supported Methods: ['generateContent', 'countTokens']\n",
      "--------------------\n",
      "Model Name: models/gemini-1.5-flash-8b-exp-0924\n",
      "  Display Name: Gemini 1.5 Flash 8B Experimental 0924\n",
      "  Description: Experimental release (September 24th, 2024) of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model. Replaced by Gemini-1.5-flash-8b-001 (stable).\n",
      "  Supported Methods: ['generateContent', 'countTokens']\n",
      "--------------------\n",
      "Model Name: models/gemini-2.5-pro-exp-03-25\n",
      "  Display Name: Gemini 2.5 Pro Experimental 03-25\n",
      "  Description: Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
      "  Supported Methods: ['generateContent', 'countTokens']\n",
      "--------------------\n",
      "Model Name: models/gemini-2.0-flash-exp\n",
      "  Display Name: Gemini 2.0 Flash Experimental\n",
      "  Description: Gemini 2.0 Flash Experimental\n",
      "  Supported Methods: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "--------------------\n",
      "Model Name: models/gemini-2.0-flash\n",
      "  Display Name: Gemini 2.0 Flash\n",
      "  Description: Gemini 2.0 Flash\n",
      "  Supported Methods: ['generateContent', 'countTokens']\n",
      "--------------------\n",
      "Model Name: models/gemini-2.0-flash-001\n",
      "  Display Name: Gemini 2.0 Flash 001\n",
      "  Description: Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.\n",
      "  Supported Methods: ['generateContent', 'countTokens']\n",
      "--------------------\n",
      "Model Name: models/gemini-2.0-flash-exp-image-generation\n",
      "  Display Name: Gemini 2.0 Flash (Image Generation) Experimental\n",
      "  Description: Gemini 2.0 Flash (Image Generation) Experimental\n",
      "  Supported Methods: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "--------------------\n",
      "Model Name: models/gemini-2.0-flash-lite-001\n",
      "  Display Name: Gemini 2.0 Flash-Lite 001\n",
      "  Description: Stable version of Gemini 2.0 Flash Lite\n",
      "  Supported Methods: ['generateContent', 'countTokens']\n",
      "--------------------\n",
      "Model Name: models/gemini-2.0-flash-lite\n",
      "  Display Name: Gemini 2.0 Flash-Lite\n",
      "  Description: Gemini 2.0 Flash-Lite\n",
      "  Supported Methods: ['generateContent', 'countTokens']\n",
      "--------------------\n",
      "Model Name: models/gemini-2.0-flash-lite-preview-02-05\n",
      "  Display Name: Gemini 2.0 Flash-Lite Preview 02-05\n",
      "  Description: Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite\n",
      "  Supported Methods: ['generateContent', 'countTokens']\n",
      "--------------------\n",
      "Model Name: models/gemini-2.0-flash-lite-preview\n",
      "  Display Name: Gemini 2.0 Flash-Lite Preview\n",
      "  Description: Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite\n",
      "  Supported Methods: ['generateContent', 'countTokens']\n",
      "--------------------\n",
      "Model Name: models/gemini-2.0-pro-exp\n",
      "  Display Name: Gemini 2.0 Pro Experimental\n",
      "  Description: Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
      "  Supported Methods: ['generateContent', 'countTokens']\n",
      "--------------------\n",
      "Model Name: models/gemini-2.0-pro-exp-02-05\n",
      "  Display Name: Gemini 2.0 Pro Experimental 02-05\n",
      "  Description: Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
      "  Supported Methods: ['generateContent', 'countTokens']\n",
      "--------------------\n",
      "Model Name: models/gemini-exp-1206\n",
      "  Display Name: Gemini Experimental 1206\n",
      "  Description: Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
      "  Supported Methods: ['generateContent', 'countTokens']\n",
      "--------------------\n",
      "Model Name: models/gemini-2.0-flash-thinking-exp-01-21\n",
      "  Display Name: Gemini 2.0 Flash Thinking Experimental 01-21\n",
      "  Description: Experimental release (January 21st, 2025) of Gemini 2.0 Flash Thinking\n",
      "  Supported Methods: ['generateContent', 'countTokens']\n",
      "--------------------\n",
      "Model Name: models/gemini-2.0-flash-thinking-exp\n",
      "  Display Name: Gemini 2.0 Flash Thinking Experimental 01-21\n",
      "  Description: Experimental release (January 21st, 2025) of Gemini 2.0 Flash Thinking\n",
      "  Supported Methods: ['generateContent', 'countTokens']\n",
      "--------------------\n",
      "Model Name: models/gemini-2.0-flash-thinking-exp-1219\n",
      "  Display Name: Gemini 2.0 Flash Thinking Experimental\n",
      "  Description: Gemini 2.0 Flash Thinking Experimental\n",
      "  Supported Methods: ['generateContent', 'countTokens']\n",
      "--------------------\n",
      "Model Name: models/learnlm-1.5-pro-experimental\n",
      "  Display Name: LearnLM 1.5 Pro Experimental\n",
      "  Description: Alias that points to the most recent stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens.\n",
      "  Supported Methods: ['generateContent', 'countTokens']\n",
      "--------------------\n",
      "Model Name: models/gemma-3-27b-it\n",
      "  Display Name: Gemma 3 27B\n",
      "  Description: \n",
      "  Supported Methods: ['generateContent', 'countTokens']\n",
      "--------------------\n",
      "\n",
      "--- Vision Model Check ---\n",
      "âœ… Found at least one model likely capable of vision processing.\n",
      "   A suitable model name might be: 'models/gemini-1.0-pro-vision-latest' (or choose based on the list above).\n",
      "\n",
      "--- Initializing Model: gemini-1.5-flash ---\n",
      "âœ… Successfully initialized model: models/gemini-1.5-flash\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- Load API Key and Configure ---\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if not GOOGLE_API_KEY:\n",
    "    print(\"ðŸ”´ Error: GOOGLE_API_KEY not found in environment variables.\")\n",
    "    # Handle error appropriately, maybe exit\n",
    "    exit()\n",
    "else:\n",
    "    try:\n",
    "        genai.configure(api_key=GOOGLE_API_KEY)\n",
    "        print(\"âœ… Google API Configured\")\n",
    "    except Exception as e:\n",
    "        print(f\"ðŸ”´ Google configuration failed: {e}\")\n",
    "        # Handle error appropriately, maybe exit\n",
    "        exit()\n",
    "\n",
    "# --- List Available Models ---\n",
    "print(\"\\n--- Available Gemini Models ---\")\n",
    "vision_model_found = False\n",
    "vision_model_name = None # To store the name if found\n",
    "\n",
    "try:\n",
    "    # Iterate through the list of available models\n",
    "    for model in genai.list_models():\n",
    "        # The 'generateContent' method is the core method for text and multimodal input.\n",
    "        # Models supporting multimodal input (like images) will typically support 'generateContent'.\n",
    "        # We look for models explicitly named 'vision' or newer multimodal models like 1.5 flash/pro.\n",
    "        # Note: Model naming conventions can change, checking 'generateContent' is generally reliable.\n",
    "\n",
    "        # Print details for all models supporting content generation\n",
    "        if 'generateContent' in model.supported_generation_methods:\n",
    "            print(f\"Model Name: {model.name}\")\n",
    "            print(f\"  Display Name: {model.display_name}\")\n",
    "            print(f\"  Description: {model.description}\")\n",
    "            print(f\"  Supported Methods: {model.supported_generation_methods}\")\n",
    "            print(\"-\" * 20)\n",
    "\n",
    "            # Check if this model is likely vision-capable\n",
    "            # Check for 'vision' in the name or if it's one of the known multi-modal models\n",
    "            # The 'gemini-1.5-flash' and 'gemini-1.5-pro' models ARE vision capable by default.\n",
    "            if ('vision' in model.name or\n",
    "                'gemini-1.5-flash' in model.name or\n",
    "                'gemini-1.5-pro' in model.name):\n",
    "                vision_model_found = True\n",
    "                if vision_model_name is None: # Store the first likely vision model found\n",
    "                   vision_model_name = model.name\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nðŸ”´ Error listing models: {e}\")\n",
    "\n",
    "# --- Report Findings ---\n",
    "print(\"\\n--- Vision Model Check ---\")\n",
    "if vision_model_found:\n",
    "    print(f\"âœ… Found at least one model likely capable of vision processing.\")\n",
    "    print(f\"   A suitable model name might be: '{vision_model_name}' (or choose based on the list above).\")\n",
    "    # Specifically confirm 1.5-flash if it was listed\n",
    "    if 'gemini-1.5-flash' in [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]:\n",
    "         print(\"   Confirmed: 'gemini-1.5-flash' is available and supports vision.\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ Could not automatically identify a specific 'vision' model in the list.\")\n",
    "    print(\"   Please review the descriptions above. Models like 'gemini-1.5-flash' are multimodal and handle images.\")\n",
    "\n",
    "\n",
    "# --- Your Original Model Initialization (Example) ---\n",
    "# You can now choose the model name based on the list printed above\n",
    "# MODEL_NAME = vision_model_name if vision_model_name else 'gemini-1.5-flash' # Example: Use found vision model or default to flash\n",
    "MODEL_NAME = 'gemini-1.5-flash' # Sticking with flash as it's confirmed multimodal\n",
    "\n",
    "try:\n",
    "    print(f\"\\n--- Initializing Model: {MODEL_NAME} ---\")\n",
    "    model = genai.GenerativeModel(MODEL_NAME)\n",
    "    print(f\"âœ… Successfully initialized model: {model.model_name}\") # Use model.model_name to confirm\n",
    "except Exception as e:\n",
    "    print(f\"ðŸ”´ Failed to initialize selected model '{MODEL_NAME}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- Load API Key and Configure ---\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if not GOOGLE_API_KEY:\n",
    "    print(\"ðŸ”´ Error: GOOGLE_API_KEY not found in environment variables.\")\n",
    "    # Handle error appropriately, maybe exit\n",
    "    exit()\n",
    "else:\n",
    "    try:\n",
    "        genai.configure(api_key=GOOGLE_API_KEY)\n",
    "        print(\"âœ… Google API Configured\")\n",
    "    except Exception as e:\n",
    "        print(f\"ðŸ”´ Google configuration failed: {e}\")\n",
    "        # Handle error appropriately, maybe exit\n",
    "        exit()\n",
    "# --- Your Original Model Initialization (Example) ---\n",
    "# You can now choose the model name based on the list printed above\n",
    "# MODEL_NAME = vision_model_name if vision_model_name else 'gemini-1.5-flash' # Example: Use found vision model or default to flash\n",
    "MODEL_NAME = 'gemini-1.5-flash' # Sticking with flash as it's confirmed multimodal\n",
    "\n",
    "try:\n",
    "    print(f\"\\n--- Initializing Model: {MODEL_NAME} ---\")\n",
    "    model = genai.GenerativeModel(MODEL_NAME)\n",
    "    print(f\"âœ… Successfully initialized model: {model.model_name}\") # Use model.model_name to confirm\n",
    "except Exception as e:\n",
    "    print(f\"ðŸ”´ Failed to initialize selected model '{MODEL_NAME}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "chat = model.start_chat(history=[]) # Gemini uses its own history management\n",
    "image = pyautogui.screenshot()\n",
    "prompt = \"Describe this screenshot in detail. What application or window is primarily visible?\"\n",
    "\n",
    "# Prepare the content list for the API call\n",
    "# The API directly accepts PIL Image objects\n",
    "contents = [prompt, image]\n",
    "\n",
    "print(f\"âž¡ï¸ Sending image and prompt ('{prompt}') to {MODEL_NAME}...\")\n",
    "try:\n",
    "    # Use chat.send_message for conversational context\n",
    "    response = chat.send_message(contents)\n",
    "\n",
    "    # --- Process and Print Response ---\n",
    "    print(\"\\n--- LLM Response ---\")\n",
    "    # Make sure to access the text part of the response\n",
    "    print(response.text)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nðŸ”´ Error sending content to Gemini: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import sys # To increase recursion depth for potentially large images\n",
    "\n",
    "def get_pixel_grid(image_path, convert_mode='RGB'):\n",
    "    \"\"\"\n",
    "    Loads an image and returns its pixel data as a 2D list (grid).\n",
    "\n",
    "    Args:\n",
    "        image_path (str): The path to the image file.\n",
    "        convert_mode (str): The mode to convert the image to before processing.\n",
    "                              Common options: 'RGBA' (Red, Green, Blue, Alpha/Transparency),\n",
    "                              'RGB' (Red, Green, Blue), 'L' (Luminance/Grayscale).\n",
    "                              Defaults to 'RGBA' to preserve transparency info.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - list: A list of lists representing the pixel grid (grid[y][x]).\n",
    "                    Each element in the inner list is a tuple representing the\n",
    "                    pixel's color channels (e.g., (R, G, B, A) for 'RGBA').\n",
    "                    Returns None if the image cannot be opened.\n",
    "            - int: The width of the image in pixels.\n",
    "            - int: The height of the image in pixels.\n",
    "            - str: The actual mode the image was processed in (e.g., 'RGBA').\n",
    "        Returns (None, 0, 0, None) if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Increase recursion depth limit for Pillow potentially needing it\n",
    "        # on complex images or large grids, though often not necessary.\n",
    "        # Adjust limit as needed, but be mindful of stack overflow potential.\n",
    "        # sys.setrecursionlimit(2000) # Uncomment if you face recursion depth errors\n",
    "\n",
    "        img = Image.open(image_path)\n",
    "\n",
    "        # --- Convert Image Mode ---\n",
    "        # It's good practice to convert to a known mode (like RGBA or RGB)\n",
    "        # to ensure consistent pixel data format.\n",
    "        # 'RGBA' includes transparency, 'RGB' discards it.\n",
    "        # 'L' converts to grayscale.\n",
    "        img_converted = img.convert(convert_mode)\n",
    "        actual_mode = img_converted.mode\n",
    "\n",
    "        # --- Get Dimensions ---\n",
    "        width, height = img_converted.size\n",
    "        print(f\"Image loaded: '{image_path}'\")\n",
    "        print(f\"Original mode: '{img.mode}', Processing mode: '{actual_mode}'\")\n",
    "        print(f\"Dimensions: {width}x{height}\")\n",
    "\n",
    "        # --- Access Pixel Data ---\n",
    "        # img.load() provides efficient pixel access\n",
    "        pixel_data = img_converted.load()\n",
    "\n",
    "        # --- Build the Grid ---\n",
    "        pixel_grid = []\n",
    "        print(\"Building pixel grid...\")\n",
    "        for y in range(height):\n",
    "            row = []\n",
    "            for x in range(width):\n",
    "                # pixel_data[x, y] returns the pixel value at (x, y)\n",
    "                # The format depends on the mode (e.g., (R,G,B,A) for RGBA)\n",
    "                row.append(pixel_data[x, y])\n",
    "            pixel_grid.append(row)\n",
    "            # Optional: Print progress for large images\n",
    "            # if (y + 1) % 100 == 0:\n",
    "            #     print(f\"Processed row {y+1}/{height}\")\n",
    "\n",
    "        print(\"Pixel grid construction complete.\")\n",
    "        return pixel_grid, width, height, actual_mode\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Image file not found at '{image_path}'\")\n",
    "        return None, 0, 0, None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        # Uncomment the line below for more detailed error traceback\n",
    "        # import traceback; traceback.print_exc()\n",
    "        return None, 0, 0, None\n",
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with the actual path to your image file\n",
    "    image_file = 'image.png' # Or .jpg, .jpeg, .bmp, .gif, etc.\n",
    "\n",
    "    # Get the grid (using RGBA mode by default)\n",
    "    grid, w, h, mode = get_pixel_grid(image_file)\n",
    "\n",
    "    if grid:\n",
    "        print(f\"\\nSuccessfully created grid for {image_file} ({w}x{h}, Mode: {mode})\")\n",
    "\n",
    "        # --- Displaying a small part of the grid (optional) ---\n",
    "        # Be careful printing the whole grid for large images - it will be huge!\n",
    "        print(\"\\nPixel data for top-left 5x5 area (or smaller if image is smaller):\")\n",
    "        max_print_rows = max(5, h)\n",
    "        max_print_cols = max(5, w)\n",
    "\n",
    "        for y in range(max_print_rows):\n",
    "            row_str_parts = []\n",
    "            for x in range(max_print_cols):\n",
    "                # grid[y][x] accesses the pixel at column x, row y\n",
    "                row_str_parts.append(str(grid[y][x]))\n",
    "            print(f\"Row {y}: {' '.join(row_str_parts)}\")\n",
    "\n",
    "        # --- Accessing a specific pixel ---\n",
    "        if w > 10 and h > 10:\n",
    "            try:\n",
    "                # Remember: grid[row_index][column_index] -> grid[y][x]\n",
    "                pixel_at_10_10 = grid[10][10]\n",
    "                print(f\"\\nPixel value at (x=10, y=10): {pixel_at_10_10}\")\n",
    "            except IndexError:\n",
    "                 print(\"\\nImage is smaller than 11x11, cannot access pixel (10, 10).\")\n",
    "    else:\n",
    "        print(f\"\\nFailed to create pixel grid for {image_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import sys # To increase recursion depth for potentially large images\n",
    "import os  # To check file paths\n",
    "\n",
    "# Note: Increased default convert_mode to 'RGBA' in get_pixel_grid\n",
    "#       to better handle transparency by default. You can change it back\n",
    "#       to 'RGB' if you prefer to discard transparency.\n",
    "def get_pixel_grid(image_path, convert_mode='RGBA'):\n",
    "    \"\"\"\n",
    "    Loads an image and returns its pixel data as a 2D list (grid).\n",
    "\n",
    "    Args:\n",
    "        image_path (str): The path to the image file.\n",
    "        convert_mode (str): The mode to convert the image to before processing.\n",
    "                              Common options: 'RGBA', 'RGB', 'L'.\n",
    "                              Defaults to 'RGBA'.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (pixel_grid, width, height, actual_mode) or (None, 0, 0, None) on error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(image_path):\n",
    "             raise FileNotFoundError(f\"Input image file not found at '{image_path}'\")\n",
    "\n",
    "        img = Image.open(image_path)\n",
    "        img_converted = img.convert(convert_mode)\n",
    "        actual_mode = img_converted.mode\n",
    "        width, height = img_converted.size\n",
    "\n",
    "        print(f\"Image loaded: '{image_path}'\")\n",
    "        print(f\"Original mode: '{img.mode}', Processing mode: '{actual_mode}'\")\n",
    "        print(f\"Dimensions: {width}x{height}\")\n",
    "\n",
    "        pixel_data = img_converted.load() # Efficient pixel access\n",
    "\n",
    "        pixel_grid = []\n",
    "        print(\"Building pixel grid...\")\n",
    "        # Create grid using list comprehension (often slightly faster)\n",
    "        pixel_grid = [[pixel_data[x, y] for x in range(width)] for y in range(height)]\n",
    "        # Equivalent loop structure:\n",
    "        # for y in range(height):\n",
    "        #     row = []\n",
    "        #     for x in range(width):\n",
    "        #         row.append(pixel_data[x, y])\n",
    "        #     pixel_grid.append(row)\n",
    "\n",
    "        print(\"Pixel grid construction complete.\")\n",
    "        return pixel_grid, width, height, actual_mode\n",
    "\n",
    "    except FileNotFoundError as fnf_error:\n",
    "        print(f\"Error: {fnf_error}\")\n",
    "        return None, 0, 0, None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during grid creation: {e}\")\n",
    "        # import traceback; traceback.print_exc() # Uncomment for detailed errors\n",
    "        return None, 0, 0, None\n",
    "\n",
    "\n",
    "def create_image_from_grid(pixel_grid, width, height, mode, output_path):\n",
    "    \"\"\"\n",
    "    Creates and saves an image file from a pixel grid.\n",
    "\n",
    "    Args:\n",
    "        pixel_grid (list): A list of lists (rows) containing pixel tuples.\n",
    "                           Example: [[(r,g,b), (r,g,b)], [(r,g,b), (r,g,b)]]\n",
    "        width (int): The desired width of the output image.\n",
    "        height (int): The desired height of the output image.\n",
    "        mode (str): The mode of the pixel data (e.g., 'RGB', 'RGBA', 'L').\n",
    "                    This MUST match the format of tuples in the pixel_grid.\n",
    "        output_path (str): The path where the new image file will be saved.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the image was created and saved successfully, False otherwise.\n",
    "    \"\"\"\n",
    "    print(f\"\\nAttempting to create image from grid (Mode: {mode}, Size: {width}x{height})...\")\n",
    "    try:\n",
    "        # --- Basic Validation ---\n",
    "        if not pixel_grid:\n",
    "            print(\"Error: Pixel grid is empty.\")\n",
    "            return False\n",
    "        if len(pixel_grid) != height:\n",
    "            print(f\"Error: Grid height ({len(pixel_grid)}) does not match expected height ({height}).\")\n",
    "            return False\n",
    "        if not pixel_grid[0] or len(pixel_grid[0]) != width:\n",
    "             print(f\"Error: Grid width ({len(pixel_grid[0]) if pixel_grid[0] else 0}) does not match expected width ({width}).\")\n",
    "             return False\n",
    "\n",
    "        # --- Create New Image ---\n",
    "        # Image.new requires mode and size (width, height tuple)\n",
    "        img = Image.new(mode, (width, height))\n",
    "\n",
    "        # --- Populate Image Data ---\n",
    "        # We need to flatten the grid list for putdata()\n",
    "        # putdata expects a sequence of pixels, row by row\n",
    "        flat_pixel_list = [pixel for row in pixel_grid for pixel in row]\n",
    "\n",
    "        # Check if the flattened list size matches expected size\n",
    "        if len(flat_pixel_list) != width * height:\n",
    "             print(f\"Error: Flattened pixel data size ({len(flat_pixel_list)}) does not match expected size ({width * height}). Check grid consistency.\")\n",
    "             return False\n",
    "\n",
    "        img.putdata(flat_pixel_list)\n",
    "\n",
    "        # --- Save the Image ---\n",
    "        # Pillow determines the format from the file extension in output_path\n",
    "        img.save(output_path)\n",
    "        print(f\"Image successfully created and saved to '{output_path}'\")\n",
    "        return True\n",
    "\n",
    "    except ValueError as ve:\n",
    "        # Often occurs if pixel tuple format doesn't match the 'mode'\n",
    "        print(f\"Error creating image: {ve}. Check if pixel data format matches the mode ('{mode}').\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during image creation/saving: {e}\")\n",
    "        # import traceback; traceback.print_exc() # Uncomment for detailed errors\n",
    "        return False\n",
    "\n",
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Configuration ---\n",
    "    # Replace with the actual path to your image file\n",
    "    input_image_file = 'image.png' # Or .jpg, .jpeg, .bmp, .gif, etc.\n",
    "    # Choose the mode ('RGB', 'RGBA', 'L', etc.)\n",
    "    processing_mode = 'F' # Try 'RGB' or 'RGBA'\n",
    "    # Define the output filename\n",
    "    output_image_file = f'reconstructed_{processing_mode.lower()}_image.png'\n",
    "\n",
    "\n",
    "    # --- Step 1: Get the pixel grid from the input image ---\n",
    "    grid, w, h, mode = get_pixel_grid(input_image_file, convert_mode=processing_mode)\n",
    "\n",
    "    if grid:\n",
    "        print(f\"\\nSuccessfully created grid for '{input_image_file}' ({w}x{h}, Mode: '{mode}')\")\n",
    "\n",
    "        # Optional: Display a small part of the grid\n",
    "        # print(\"\\nPixel data sample (top-left 5x5):\")\n",
    "        # max_print_rows = min(5, h)\n",
    "        # max_print_cols = min(5, w)\n",
    "        # for y in range(max_print_rows):\n",
    "        #     row_str_parts = [str(grid[y][x]) for x in range(max_print_cols)]\n",
    "        #     print(f\"Row {y}: {' '.join(row_str_parts)}\")\n",
    "\n",
    "        # --- Step 2: Create a new image from the grid ---\n",
    "        success = create_image_from_grid(grid, w, h, mode, output_image_file)\n",
    "\n",
    "        if success:\n",
    "            print(f\"\\nReconstruction process complete. Check '{output_image_file}'.\")\n",
    "        else:\n",
    "            print(f\"\\nFailed to reconstruct image from grid.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"\\nCould not create pixel grid for '{input_image_file}'. Cannot proceed with reconstruction.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jarvis2.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
